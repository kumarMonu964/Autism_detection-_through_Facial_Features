{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12709196,"sourceType":"datasetVersion","datasetId":8032443}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-08T10:28:23.720393Z","iopub.execute_input":"2025-08-08T10:28:23.720786Z","iopub.status.idle":"2025-08-08T10:28:25.252257Z","shell.execute_reply.started":"2025-08-08T10:28:23.720757Z","shell.execute_reply":"2025-08-08T10:28:25.251318Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **MLflow Setup**","metadata":{}},{"cell_type":"code","source":"# install mlflow\n!pip install mlflow --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T09:39:25.569048Z","iopub.execute_input":"2025-08-10T09:39:25.569266Z","iopub.status.idle":"2025-08-10T09:39:37.131761Z","shell.execute_reply.started":"2025-08-10T09:39:25.569245Z","shell.execute_reply":"2025-08-10T09:39:37.131098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# install pyngrok to expose mlflow UI\n!pip install pyngrok --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T09:39:37.133236Z","iopub.execute_input":"2025-08-10T09:39:37.133495Z","iopub.status.idle":"2025-08-10T09:39:40.460448Z","shell.execute_reply.started":"2025-08-10T09:39:37.133471Z","shell.execute_reply":"2025-08-10T09:39:40.459682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pyngrok import ngrok\n# Start MLflow UI server in background\nget_ipython().system_raw(\"mlflow ui --port 5000 &\")\n\n# created a ngrok account and authenticated\nngrok.set_auth_token(\"30pLtpE03zO9a3mgzMsIeykbCNI_2N9HxvHKvSBt8tFtLec2W\")\n\nfrom pyngrok import ngrok\n# kill any existing tunnels\nngrok.kill()\npublic_url = ngrok.connect(5000)\nprint(f\"MLflow UI URL: {public_url.public_url}\")\n\nimport mlflow\n# Set tracking URI to public ngrok URL or localhost if running locally\nmlflow.set_tracking_uri(public_url.public_url)  # or \"http://localhost:5000\" if no ngrok\nmlflow.set_experiment(\"AutismDetection-Classifier\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T09:42:56.709296Z","iopub.execute_input":"2025-08-10T09:42:56.709585Z","iopub.status.idle":"2025-08-10T09:42:57.402960Z","shell.execute_reply.started":"2025-08-10T09:42:56.709562Z","shell.execute_reply":"2025-08-10T09:42:57.402278Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Loading and Basic EDA**","metadata":{}},{"cell_type":"code","source":"# define the train directory\nimport os\npath = '/kaggle/input/autism/autism_split'\ntrain_dir = os.path.join(path,'train')\nprint(train_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:01.700136Z","iopub.execute_input":"2025-08-12T13:31:01.700514Z","iopub.status.idle":"2025-08-12T13:31:01.709303Z","shell.execute_reply.started":"2025-08-12T13:31:01.700480Z","shell.execute_reply":"2025-08-12T13:31:01.708430Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/autism/autism_split/train\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# count of the images in each folder of train and test\npath = path\ntrain_folder = os.path.join(path,'train')\ntrain_a_folder = os.path.join(train_folder,'autistic')\ntrain_na_folder = os.path.join(train_folder,'non_autistic')\n\nval_folder = os.path.join(path,'val')\nval_a_folder = os.path.join(val_folder,'autistic')\nval_na_folder = os.path.join(val_folder,'non_autistic')\n\ntest_folder = os.path.join(path,'test')\ntest_a_folder = os.path.join(test_folder,'autistic')\ntest_na_folder = os.path.join(test_folder,'non_autistic')\n\n# count train\ntrain_a_count = len(os.listdir(train_a_folder))\ntrain_na_count = len(os.listdir(train_na_folder))\n\n# count test\nval_a_count = len(os.listdir(val_a_folder))\nval_na_count = len(os.listdir(val_na_folder))\n\n# count train\ntest_a_count = len(os.listdir(test_a_folder))\ntest_na_count = len(os.listdir(test_na_folder))\n\n# print train\nprint('---------------In TRAIN folder----------')\nprint(\"Number of autistic images:\", train_a_count)\nprint(\"Number of non_autistic images:\", train_na_count)\n# print val\nprint('\\n\\n---------------In VAL folder----------')\nprint(\"Number of autistic images:\", val_a_count)\nprint(\"Number of non_autistic images:\", val_na_count)\n# print test\nprint('\\n\\n---------------In TEST folder----------')\nprint(\"Number of autistic images:\", test_a_count)\nprint(\"Number of non_autistic images:\", test_na_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:04.885606Z","iopub.execute_input":"2025-08-12T13:31:04.885863Z","iopub.status.idle":"2025-08-12T13:31:05.010725Z","shell.execute_reply.started":"2025-08-12T13:31:04.885843Z","shell.execute_reply":"2025-08-12T13:31:05.009927Z"}},"outputs":[{"name":"stdout","text":"---------------In TRAIN folder----------\nNumber of autistic images: 2335\nNumber of non_autistic images: 2335\n\n\n---------------In VAL folder----------\nNumber of autistic images: 584\nNumber of non_autistic images: 584\n\n\n---------------In TEST folder----------\nNumber of autistic images: 12\nNumber of non_autistic images: 12\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nbase_dir = path   # update this path\n\nfor split in ['train', 'val', 'test']:\n    for cls in ['autistic', 'non_autistic']:\n        cls_dir = os.path.join(base_dir, split, cls)\n        img_files = [f for f in os.listdir(cls_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\n        # Select up to 3 images to show as subplots\n        plt.figure(figsize=(4,7))\n        n_images = min(3, len(img_files))\n        fig, axs = plt.subplots(1, n_images, figsize=(5 * n_images, 5))\n        fig.suptitle(f\"{split} - {cls}\")\n\n        for i in range(n_images):\n            img_path = os.path.join(cls_dir, img_files[i])\n            img = Image.open(img_path)\n            axs[i].imshow(img)\n            axs[i].set_title(img_files[i])\n            axs[i].axis('off')\n\n        plt.tight_layout()\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:58:54.677780Z","iopub.execute_input":"2025-08-11T12:58:54.678466Z","iopub.status.idle":"2025-08-11T12:58:58.161710Z","shell.execute_reply.started":"2025-08-11T12:58:54.678431Z","shell.execute_reply":"2025-08-11T12:58:58.160423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Generator for Model pipelining the data**","metadata":{}},{"cell_type":"code","source":"train_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:43:17.070761Z","iopub.execute_input":"2025-08-11T11:43:17.071067Z","iopub.status.idle":"2025-08-11T11:43:17.078896Z","shell.execute_reply.started":"2025-08-11T11:43:17.071045Z","shell.execute_reply":"2025-08-11T11:43:17.077344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data flow from directory\nimport tensorflow as tf\n\n\n\n# Load train data\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    labels='inferred',\n    label_mode='binary',        # for binary classification (0/1)\n    image_size=(224,224),\n    batch_size=32,\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:43:20.092295Z","iopub.execute_input":"2025-08-11T11:43:20.092622Z","iopub.status.idle":"2025-08-11T11:43:43.021504Z","shell.execute_reply.started":"2025-08-11T11:43:20.092590Z","shell.execute_reply":"2025-08-11T11:43:43.020523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the val directory\nval_dir = os.path.join(path,'val')\nval_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:43:43.022891Z","iopub.execute_input":"2025-08-11T11:43:43.023618Z","iopub.status.idle":"2025-08-11T11:43:43.029184Z","shell.execute_reply.started":"2025-08-11T11:43:43.023588Z","shell.execute_reply":"2025-08-11T11:43:43.028112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load the validation data\n\nval_dataset = tf.keras.utils.image_dataset_from_directory(\n    val_dir,\n    labels='inferred',\n    label_mode='binary',        # for binary classification (0/1)\n    image_size=(224,224),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:44:11.534920Z","iopub.execute_input":"2025-08-11T11:44:11.535280Z","iopub.status.idle":"2025-08-11T11:44:12.589047Z","shell.execute_reply.started":"2025-08-11T11:44:11.535257Z","shell.execute_reply":"2025-08-11T11:44:12.588098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MLflow tracking and logging function","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport tempfile\nimport os\n\ndef train_and_log_model(model, model_name, train_ds, val_ds, epochs=5, optimizer='adam'):\n    with mlflow.start_run(run_name=model_name):\n\n        # log model parameters\n        mlflow.log_param(\"model_name\", model_name)\n        mlflow.log_param(\"optimizer\", optimizer)\n        mlflow.log_param(\"epochs\", epochs)\n\n        # compile the model\n        model.compile(optimizer=optimizer,\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\n\n        # train the model\n        history = model.fit(train_ds,\n                            validation_data=val_ds,\n                            epochs=epochs)\n\n        # log final metrics\n        mlflow.log_metrics({\n            \"train_accuracy\": history.history['accuracy'][-1],\n            \"val_accuracy\": history.history['val_accuracy'][-1],\n            \"train_loss\": history.history['loss'][-1],\n            \"val_loss\": history.history['val_loss'][-1]\n        })\n\n        # Get predictions and labels for confusion matrix\n        y_true = []\n        y_pred = []\n        for X_batch, y_batch in val_ds:\n            preds = model.predict(X_batch,verbose=0)\n            y_true.extend(y_batch.numpy())\n            y_pred.extend(np.round(preds).flatten())\n\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n\n        # Confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        fig, ax = plt.subplots(figsize=(5, 5))\n        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Autistic', 'Autistic'], yticklabels=['Non-Autistic', 'Autistic'])\n        plt.ylabel(\"Actual\")\n        plt.xlabel(\"Predicted\")\n        \n        # Save confusion matrix image\n        temp_dir = tempfile.mkdtemp()\n        cm_path = os.path.join(temp_dir, \"confusion_matrix.png\")\n        plt.savefig(cm_path)\n        plt.close()\n        mlflow.log_artifact(cm_path, artifact_path=\"plots\")\n\n        # Classification report\n        clf_report = classification_report(y_true, y_pred, target_names=['Non-Autistic', 'Autistic'])\n        report_path = os.path.join(temp_dir, \"classification_report.txt\")\n        with open(report_path, \"w\") as f:\n            f.write(clf_report)\n        mlflow.log_artifact(report_path, artifact_path=\"reports\")\n\n        # Log model\n        mlflow.keras.log_model(model, \"model\")\n        print(f\"Model: {model_name} and its metrics, confusion matrix, and report logged to MLflow.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:07:41.015417Z","iopub.execute_input":"2025-08-10T10:07:41.015726Z","iopub.status.idle":"2025-08-10T10:07:41.024589Z","shell.execute_reply.started":"2025-08-10T10:07:41.015696Z","shell.execute_reply":"2025-08-10T10:07:41.023822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **LeNet**","metadata":{}},{"cell_type":"code","source":"# import packages\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# define the model\ndef build_lenet(input_shape=(224,224,3)):\n  model = models.Sequential()\n\n  # normalization of input images\n  model.add(layers.Rescaling(1./255, input_shape=input_shape))\n\n  # layer 1\n  model.add(layers.Conv2D(6,kernel_size=(5,5),activation='relu',padding='same'))\n  model.add(layers.AveragePooling2D(pool_size=(2,2)))\n\n  # layer 2\n  model.add(layers.Conv2D(16, kernel_size=(5,5),activation='relu'))\n  model.add(layers.AveragePooling2D(pool_size=(2,2)))\n\n  # layer 3\n  model.add(layers.Flatten())\n  model.add(layers.Dense(120,activation='relu'))\n\n  # layer 4\n  model.add(layers.Dense(64,activation='relu'))\n\n  # layer 5\n  model.add(layers.Dense(1,activation='sigmoid'))\n\n  return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:07:42.564309Z","iopub.execute_input":"2025-08-10T10:07:42.564586Z","iopub.status.idle":"2025-08-10T10:07:42.570244Z","shell.execute_reply.started":"2025-08-10T10:07:42.564565Z","shell.execute_reply":"2025-08-10T10:07:42.569486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train and track\n# Set experiment ONCE at the start of your notebook/script\nmlflow.set_experiment(\"Autism_Face_Classifier\")\n\n# call the model to build\nlenet_model = build_lenet()\n\n# start model training and model logging\ntrain_and_log_model(lenet_model,\"LeNet-5\",train_dataset,val_dataset,epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:08:18.634849Z","iopub.execute_input":"2025-08-10T10:08:18.635365Z","iopub.status.idle":"2025-08-10T10:09:26.539155Z","shell.execute_reply.started":"2025-08-10T10:08:18.635344Z","shell.execute_reply":"2025-08-10T10:09:26.538544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **AlexNet**","metadata":{}},{"cell_type":"code","source":"def build_alexnet(input_shape=(224,224,3), num_classes=1):\n  model= models.Sequential()\n\n  # normalization\n  model.add(layers.Rescaling(1./255, input_shape=input_shape))\n\n  # 1st conv layer\n  model.add(layers.Conv2D(96,(11,11),strides=4,activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=2))\n\n  # 2nd Convolutional Layer\n  model.add(layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # 3rd, 4th, and 5th Convolutional Layers\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # Flatten\n  model.add(layers.Flatten())\n\n  # 1st Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n  model.add(layers.Dropout(0.5))\n\n  # 2nd Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n  model.add(layers.Dropout(0.5))\n\n  # Output Layer\n  model.add(layers.Dense(num_classes, activation='sigmoid'))\n\n  return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:10:23.160154Z","iopub.execute_input":"2025-08-10T10:10:23.160664Z","iopub.status.idle":"2025-08-10T10:10:23.167337Z","shell.execute_reply.started":"2025-08-10T10:10:23.160640Z","shell.execute_reply":"2025-08-10T10:10:23.166653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train and track for alexnet\n\n# call the model\nalexnet_model = build_alexnet()\n\n# track and log \ntrain_and_log_model(alexnet_model,\"AlexNet\",train_dataset, val_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:10:27.134684Z","iopub.execute_input":"2025-08-10T10:10:27.135232Z","iopub.status.idle":"2025-08-10T10:19:57.506161Z","shell.execute_reply.started":"2025-08-10T10:10:27.135207Z","shell.execute_reply":"2025-08-10T10:19:57.504827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **VGG16**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef build_vgg16(input_shape=(224, 224, 3), num_classes=2):\n \n    model = models.Sequential()\n\n    # Block 1\n    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',input_shape=input_shape))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Block 2\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Block 3\n    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Block 4\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Block 5\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # Fully Connected layers\n    model.add(layers.Flatten())\n    model.add(layers.Dense(4096, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(4096, activation='relu'))\n    model.add(layers.Dropout(0.5))\n\n    # Output layer\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    # Compile\n    loss_fn = 'binary_crossentropy' \n    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:57:53.805074Z","iopub.execute_input":"2025-08-10T07:57:53.805360Z","iopub.status.idle":"2025-08-10T07:57:53.815631Z","shell.execute_reply.started":"2025-08-10T07:57:53.805337Z","shell.execute_reply":"2025-08-10T07:57:53.815001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train and track for alexnet\n\n# call the model\nvgg_model = build_vgg16()\n\n# track and log \ntrain_and_log_model(vgg_model,\"VGG16\",train_dataset, val_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:57:58.110079Z","iopub.execute_input":"2025-08-10T07:57:58.110314Z","iopub.status.idle":"2025-08-10T08:01:30.551319Z","shell.execute_reply.started":"2025-08-10T07:57:58.110297Z","shell.execute_reply":"2025-08-10T08:01:30.548003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **VGG16 transfer learning**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\n\ndef build_vgg16_transfer(input_shape=(224,224,3), num_classes=1, freeze_conv=True):\n\n    # Load VGG16 without the top fully-connected layers\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n\n    # Freeze convolutional layers if required\n    if freeze_conv:\n        for layer in base_model.layers:\n            layer.trainable = False\n\n    # Build new model on top\n    model = models.Sequential()\n    model.add(layers.Rescaling(1./255, input_shape=input_shape))  # normalize inputs\n    model.add(base_model)\n    model.add(layers.Flatten())\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(num_classes, activation='sigmoid'))  # binary classification\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:24:08.394915Z","iopub.execute_input":"2025-08-10T10:24:08.395716Z","iopub.status.idle":"2025-08-10T10:24:08.407423Z","shell.execute_reply.started":"2025-08-10T10:24:08.395686Z","shell.execute_reply":"2025-08-10T10:24:08.406733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train and track for alexnet\n\n# call the model\nvgg_model_transfer = build_vgg16_transfer()\n\n# track and log \ntrain_and_log_model(vgg_model_transfer,\"VGG16_transfer\",train_dataset, val_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:24:43.784137Z","iopub.execute_input":"2025-08-10T10:24:43.784692Z","iopub.status.idle":"2025-08-10T10:29:11.330880Z","shell.execute_reply.started":"2025-08-10T10:24:43.784667Z","shell.execute_reply":"2025-08-10T10:29:11.330265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **USING DATA AUGMENTATION, L2 REGULARIZATION AND DROPOUTS for robust model**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, regularizers\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport mlflow\nimport mlflow.keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data augmentation pipeline\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.RandomTranslation(0.1, 0.1),\n    layers.RandomContrast(0.1)\n])\n\ndef train_and_log_model_aug(model_fn, model_name, train_ds, val_ds, epochs=5, optimizer='adam'):\n\n    with mlflow.start_run(run_name=model_name):\n        \n        # Build model with augmentation & regularization\n        input_shape = (224, 224, 3)\n        model = tf.keras.Sequential([\n            data_augmentation,\n            layers.Rescaling(1./255, input_shape=input_shape),\n            model_fn(input_shape=input_shape),  # your base model\n            layers.Dropout(0.5),\n            layers.Dense(1, activation='sigmoid',\n                         kernel_regularizer=regularizers.l2(0.01))\n        ])\n        \n        # Compile\n        model.compile(optimizer=optimizer,\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\n        \n        # Train\n        history = model.fit(train_ds,\n                            validation_data=val_ds,\n                            epochs=epochs)\n        \n        # Log params\n        mlflow.log_param(\"model_name\", model_name)\n        mlflow.log_param(\"optimizer\", optimizer)\n        mlflow.log_param(\"epochs\", epochs)\n        \n        # Log final metrics\n        mlflow.log_metrics({\n            \"train_accuracy\": history.history['accuracy'][-1],\n            \"val_accuracy\": history.history['val_accuracy'][-1],\n            \"train_loss\": history.history['loss'][-1],\n            \"val_loss\": history.history['val_loss'][-1]\n        })\n        \n        # Predictions for confusion matrix\n        y_true = np.concatenate([y for x, y in val_ds], axis=0)\n        y_pred_probs = model.predict(val_ds, verbose=0)\n        y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n        \n        # Confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        fig, ax = plt.subplots()\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                    xticklabels=['Non_Autistic', 'Autistic'],\n                    yticklabels=['Non_Autistic', 'Autistic'])\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        \n        # Save CM figure\n        cm_path = \"confusion_matrix.png\"\n        plt.savefig(cm_path)\n        mlflow.log_artifact(cm_path)\n        \n        # Classification report\n        report = classification_report(y_true, y_pred, target_names=['Non_Autistic', 'Autistic'], output_dict=True)\n        report_path = \"classification_report.txt\"\n        with open(report_path, \"w\") as f:\n            f.write(classification_report(y_true, y_pred, target_names=['Non_Autistic', 'Autistic']))\n        mlflow.log_artifact(report_path)\n        \n        # Log model\n        mlflow.keras.log_model(model, \"model\")\n        print(f\"✅ Model '{model_name}' trained and logged with MLflow.\")\n    \n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:21:23.271361Z","iopub.execute_input":"2025-08-12T07:21:23.271989Z","iopub.status.idle":"2025-08-12T07:21:36.583814Z","shell.execute_reply.started":"2025-08-12T07:21:23.271966Z","shell.execute_reply":"2025-08-12T07:21:36.582855Z"}},"outputs":[{"name":"stderr","text":"2025-08-12 07:21:24.633568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754983284.817160      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754983284.870826      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/524085971.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"],"ename":"ModuleNotFoundError","evalue":"No module named 'mlflow'","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"## 1) **LeNet-5**","metadata":{}},{"cell_type":"code","source":"# build leNet model but with data augmentation, l2 reg and dropouts\ndef build_lenet(input_shape=(224, 224, 3)):\n    from tensorflow.keras import layers, models\n    \n    model = models.Sequential()\n\n    # Layer 1\n    model.add(layers.Conv2D(6, kernel_size=(5,5), activation='relu', padding='same', input_shape=input_shape))\n    model.add(layers.AveragePooling2D(pool_size=(2,2)))\n\n    # Layer 2\n    model.add(layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\n    model.add(layers.AveragePooling2D(pool_size=(2,2)))\n\n    # Flatten + Dense layers\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(64, activation='relu'))\n\n    return model\n\n# call model building and tracking\ntrain_and_log_model_aug(build_lenet, \"LeNet-5_aug\",train_dataset,val_dataset,epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:32:13.268752Z","iopub.execute_input":"2025-08-10T10:32:13.269059Z","iopub.status.idle":"2025-08-10T10:33:02.564499Z","shell.execute_reply.started":"2025-08-10T10:32:13.269039Z","shell.execute_reply":"2025-08-10T10:33:02.563779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) **AlexNet**","metadata":{}},{"cell_type":"code","source":"def build_alexnet(input_shape=(224,224,3), num_classes=2):\n  model= models.Sequential()\n\n  # normalization\n  model.add(layers.Rescaling(1./255, input_shape=input_shape))\n\n  # 1st conv layer\n  model.add(layers.Conv2D(96,(11,11),strides=4,activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=2))\n\n  # 2nd Convolutional Layer\n  model.add(layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # 3rd, 4th, and 5th Convolutional Layers\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # Flatten\n  model.add(layers.Flatten())\n\n  # 1st Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n\n  # 2nd Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n\n  # Output Layer\n  model.add(layers.Dense(num_classes, activation='sigmoid'))\n\n  return model\n\ntrain_and_log_model_aug(build_alexnet,\"AlexNet_aug\",train_dataset,val_dataset,epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:36:24.509148Z","iopub.execute_input":"2025-08-10T10:36:24.509880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Without MLflow","metadata":{}},{"cell_type":"code","source":"# Load train data\nimport tensorflow as tf\n\n# define the train directory\nimport os\npath = '/kaggle/input/autism/autism_split'\ntrain_dir = os.path.join(path,'train')\nval_dir = os.path.join(path,'val')\n\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(\ntrain_dir,\nlabels='inferred',\nlabel_mode='binary', # for binary classification (0/1)\nimage_size=(224,224),\nbatch_size=32,\nshuffle=True\n)\n\nval_dataset = tf.keras.utils.image_dataset_from_directory(\nval_dir,\nlabels='inferred',\nlabel_mode='binary', # for binary classification (0/1)\nimage_size=(224,224),\nbatch_size=32,\nshuffle=False\n)\n\n# Optional: cache + prefetch for performance\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n\nfrom tensorflow.keras import layers\n\ndata_augmentation = tf.keras.Sequential([\nlayers.RandomFlip(\"horizontal\"), # mirror flip\nlayers.RandomRotation(0.1), # small rotations\nlayers.RandomZoom(0.1), # zoom in/out\nlayers.RandomTranslation(0.1, 0.1), # shift images\nlayers.RandomContrast(0.1), # adjust contrast\n])\n\n\n\ntrain_dataset = train_dataset.map(\nlambda x, y: (data_augmentation(x, training=True), y),\nnum_parallel_calls=tf.data.AUTOTUNE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:14.361284Z","iopub.execute_input":"2025-08-12T13:31:14.361898Z","iopub.status.idle":"2025-08-12T13:31:38.198848Z","shell.execute_reply.started":"2025-08-12T13:31:14.361871Z","shell.execute_reply":"2025-08-12T13:31:38.198053Z"}},"outputs":[{"name":"stderr","text":"2025-08-12 13:31:16.154508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755005476.365462      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755005476.435405      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 4670 files belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1755005494.565542      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Found 1168 files belonging to 2 classes.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Plot training history function (reuse from previous answer)\ndef plot_training_history(history):\n    plt.figure(figsize=(14, 5))\n\n    # Accuracy subplot\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    if 'val_accuracy' in history.history:\n        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy over epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Loss subplot\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    if 'val_loss' in history.history:\n        plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss over epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.show()\n\n# Evaluate and show classification report and confusion matrix\ndef evaluate_and_report(model, val_dataset, class_names):\n    y_true = []\n    y_pred = []\n    for images, labels in val_dataset:\n        preds = model.predict(images, verbose=0)\n        preds_labels = (preds > 0.5).astype(int).flatten()\n        y_pred.extend(preds_labels)\n        y_true.extend(labels.numpy() if hasattr(labels, 'numpy') else labels)\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    print(\"Classification Report:\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:38.200265Z","iopub.execute_input":"2025-08-12T13:31:38.200553Z","iopub.status.idle":"2025-08-12T13:31:38.207836Z","shell.execute_reply.started":"2025-08-12T13:31:38.200533Z","shell.execute_reply":"2025-08-12T13:31:38.207157Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **LeNet-5**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\n# Your LeNet definition\ndef build_lenet(input_shape=(224,224,3)):\n    model = models.Sequential()\n    model.add(layers.Rescaling(1./255, input_shape=input_shape))\n    model.add(layers.Conv2D(6, kernel_size=(5,5), activation='relu', padding='same'))\n    model.add(layers.AveragePooling2D(pool_size=(2,2)))\n    model.add(layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\n    model.add(layers.AveragePooling2D(pool_size=(2,2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    # Compile model for binary classification\n    model.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    \n    # Train the model\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n\n    return plot_training_history(history),evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\nbuild_lenet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:05:45.470519Z","iopub.execute_input":"2025-08-10T13:05:45.470792Z","iopub.status.idle":"2025-08-10T13:10:26.783494Z","shell.execute_reply.started":"2025-08-10T13:05:45.470772Z","shell.execute_reply":"2025-08-10T13:10:26.782665Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **AlexNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\ndef build_alexnet(input_shape=(224,224,3)):\n  model= models.Sequential()\n\n  # normalization\n  model.add(layers.Rescaling(1./255, input_shape=input_shape))\n\n  # 1st conv layer\n  model.add(layers.Conv2D(96,(11,11),strides=4,activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=2))\n\n  # 2nd Convolutional Layer\n  model.add(layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # 3rd, 4th, and 5th Convolutional Layers\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=2))\n\n  # Flatten\n  model.add(layers.Flatten())\n\n  # 1st Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n  model.add(layers.Dropout(0.5))\n\n  # 2nd Fully Connected Layer\n  model.add(layers.Dense(4096, activation='relu'))\n  model.add(layers.Dropout(0.5))\n\n  # Output Layer\n  model.add(layers.Dense(1, activation='sigmoid'))\n\n  # Compile model for binary classification\n  model.compile(\n        optimizer= Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy'])\n    \n  # Assuming train_dataset and val_dataset are prepared as in your code before\n    \n  # Train the model\n  history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n\n  return plot_training_history(history),evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\n# call and build\nbuild_alexnet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:13:02.956717Z","iopub.execute_input":"2025-08-10T13:13:02.956997Z","iopub.status.idle":"2025-08-10T13:18:00.875008Z","shell.execute_reply.started":"2025-08-10T13:13:02.956978Z","shell.execute_reply":"2025-08-10T13:18:00.874311Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **VGG-16 :- Transfer Learning**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\ndef build_vgg16_transfer(input_shape=(224, 224, 3)):\n    \n    # Load pretrained VGG16 without top layers\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = False  \n\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.Flatten())\n    model.add(layers.Dense(256, activation='relu'))\n    model.add(layers.Dense(1,activation='sigmoid'))\n\n    # Compile model for binary classification\n    model.compile(\n        optimizer= Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy'])\n    \n    # Train the model\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n    \n    return plot_training_history(history),evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\n# call and build\nbuild_vgg16_transfer()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:22:38.251033Z","iopub.execute_input":"2025-08-10T13:22:38.251304Z","iopub.status.idle":"2025-08-10T13:30:09.118979Z","shell.execute_reply.started":"2025-08-10T13:22:38.251285Z","shell.execute_reply":"2025-08-10T13:30:09.118330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **VGG16 :- Fine Tuning**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\n# Fine-tuning is done at a very low learning rate (1e-5 or 1e-6) to avoid destroying pretrained weights\nfrom tensorflow.keras.optimizers import Adam\n\ndef build_vgg16_finetune(input_shape=(224,224,3), fine_tune_at=None):\n\n    # load the base model\n    base_model = VGG16(\n        weights = 'imagenet',\n        include_top = False,\n        input_shape = input_shape\n    )\n\n    # Freeze all layers initially\n    base_model.trainable = True if fine_tune_at is not None else False\n    if fine_tune_at is not None:\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n    # build a new head\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.Flatten())\n    model.add(layers.Dense(84,activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    # Compile model for binary classification\n    model.compile(\n        optimizer= Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy'])\n    \n    # Train the model\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n    \n    return plot_training_history(history),evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\n# call and build\nbuild_vgg16_finetune(fine_tune_at=15)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:45:49.376941Z","iopub.execute_input":"2025-08-10T13:45:49.377654Z","iopub.status.idle":"2025-08-10T13:53:22.255418Z","shell.execute_reply.started":"2025-08-10T13:45:49.377605Z","shell.execute_reply":"2025-08-10T13:53:22.254666Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MobileNet**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\n\ndef build_mobilenet_finetune(input_shape=(224,224,3), fine_tune_at=None):\n    base_model = tf.keras.applications.MobileNet(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True if fine_tune_at is not None else False\n    if fine_tune_at is not None:\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:54:41.230688Z","iopub.execute_input":"2025-08-10T13:54:41.231475Z","iopub.status.idle":"2025-08-10T13:54:41.237646Z","shell.execute_reply.started":"2025-08-10T13:54:41.231448Z","shell.execute_reply":"2025-08-10T13:54:41.236823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#call for fine-tuning MobileNet, unfreeze from layer 80\nbuild_mobilenet_finetune(fine_tune_at=80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:54:47.456555Z","iopub.execute_input":"2025-08-10T13:54:47.457134Z","iopub.status.idle":"2025-08-10T13:59:48.265047Z","shell.execute_reply.started":"2025-08-10T13:54:47.457111Z","shell.execute_reply":"2025-08-10T13:59:48.264415Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ResNet50**","metadata":{}},{"cell_type":"code","source":"def build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=None):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True if fine_tune_at is not None else False\n    if fine_tune_at is not None:\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T14:06:32.524832Z","iopub.execute_input":"2025-08-10T14:06:32.525037Z","iopub.status.idle":"2025-08-10T14:06:32.538249Z","shell.execute_reply.started":"2025-08-10T14:06:32.525022Z","shell.execute_reply":"2025-08-10T14:06:32.537526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  call for fine-tuning ResNet50, unfreeze from layer 140\nbuild_resnet50_finetune(fine_tune_at=140)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T13:59:48.272534Z","iopub.execute_input":"2025-08-10T13:59:48.272735Z","iopub.status.idle":"2025-08-10T14:06:32.516848Z","shell.execute_reply.started":"2025-08-10T13:59:48.272720Z","shell.execute_reply":"2025-08-10T14:06:32.516234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **InceptionV3**","metadata":{}},{"cell_type":"code","source":"def build_inceptionv3_finetune(input_shape=(224,224,3), fine_tune_at=None):\n    base_model = tf.keras.applications.InceptionV3(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True if fine_tune_at is not None else False\n    if fine_tune_at is not None:\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=10\n    )\n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T14:06:32.518167Z","iopub.execute_input":"2025-08-10T14:06:32.518410Z","iopub.status.idle":"2025-08-10T14:06:32.524083Z","shell.execute_reply.started":"2025-08-10T14:06:32.518395Z","shell.execute_reply":"2025-08-10T14:06:32.523472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# call for fine-tuning InceptionV3, unfreeze from layer 250\nbuild_inceptionv3_finetune(fine_tune_at=250)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T14:12:55.303843Z","iopub.execute_input":"2025-08-10T14:12:55.304045Z","iopub.status.idle":"2025-08-10T14:19:01.082727Z","shell.execute_reply.started":"2025-08-10T14:12:55.304030Z","shell.execute_reply":"2025-08-10T14:19:01.081866Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **OPTIMIZING THE BEST MODEL**: ResNet50","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import classification_report\nimport seaborn as sns\nimport tempfile\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:38.208576Z","iopub.execute_input":"2025-08-12T13:31:38.208854Z","iopub.status.idle":"2025-08-12T13:31:38.621464Z","shell.execute_reply.started":"2025-08-12T13:31:38.208827Z","shell.execute_reply":"2025-08-12T13:31:38.620869Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 1) Training on a larger epoch size (epoch =30)","metadata":{}},{"cell_type":"code","source":"def build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=None):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True if fine_tune_at is not None else False\n    if fine_tune_at is not None:\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=30\n    )\n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\n#  call for fine-tuning ResNet50, unfreeze from layer 140\nbuild_resnet50_finetune(fine_tune_at=140)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:03:57.567486Z","iopub.execute_input":"2025-08-11T12:03:57.568293Z","iopub.status.idle":"2025-08-11T12:22:44.206941Z","shell.execute_reply.started":"2025-08-11T12:03:57.568234Z","shell.execute_reply":"2025-08-11T12:22:44.205836Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2) Fine-Tuning data, model and HP","metadata":{}},{"cell_type":"markdown","source":"Fewer epochs + early stopping stops overfit creep.\n\nL2 reg + dropout controls weight growth.\n\nClass weights slightly bias toward autistic recall.\n\nLR scheduler helps converge smoothly without overshooting.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=140):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n    ]\n\n    class_weights = {0: 1.2, 1: 1.0}  # Slight autistic recall boost\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=20,\n        callbacks=callbacks,\n        class_weight=class_weights\n    )\n    \n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['non-autistic', 'autistic'])\n\nbuild_resnet50_finetune(fine_tune_at=140)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T13:02:38.523934Z","iopub.execute_input":"2025-08-11T13:02:38.524535Z","iopub.status.idle":"2025-08-11T13:14:35.885396Z","shell.execute_reply.started":"2025-08-11T13:02:38.524511Z","shell.execute_reply":"2025-08-11T13:14:35.884572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=140):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.6),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n    ]\n\n    class_weights = {0: 1.2, 1: 1.0}  # Slight autistic recall boost\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=30,\n        callbacks=callbacks,\n        class_weight=class_weights\n    )\n    \n    return plot_training_history(history), evaluate_and_report(model, val_dataset, class_names=['autistic', 'non-autistic'])\n\nbuild_resnet50_finetune(fine_tune_at=120)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T13:43:10.711202Z","iopub.execute_input":"2025-08-11T13:43:10.711695Z","iopub.status.idle":"2025-08-11T13:55:03.383123Z","shell.execute_reply.started":"2025-08-11T13:43:10.711673Z","shell.execute_reply":"2025-08-11T13:55:03.382505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Assuming train_dataset and val_dataset are already defined\n# e.g. via image_dataset_from_directory\n\ndef build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=140):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n    ]\n\n    class_weights = {0: 1.2, 1: 1.0}  # Slight autistic recall boost\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=20,\n        callbacks=callbacks,\n        class_weight=class_weights\n    )\n\n    # Save model for FastAPI\n    model.save(\"model/resnet50_autism.h5\")\n    print(\"✅ Model saved at model/resnet50_autism.h5\")\n\n    return history\n\n# Example call\nhistory = build_resnet50_finetune(fine_tune_at=140)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef build_resnet50_finetune(input_shape=(224,224,3), fine_tune_at=140):\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    base_model.trainable = True\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(84, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.6),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-5),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n    ]\n\n    class_weights = {0: 1.2, 1: 1.0}  # Slight autistic recall boost\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=30,\n        callbacks=callbacks,\n        class_weight=class_weights\n    )\n\n    # Save model for FastAPI\n    model.save_weights(\"/kaggle/working/resnet50_autism_weights.weights.h5\")\n    print(\"✅ Model saved at model/resnet50_autism.h5\")\n    \n    return model\n\n# build_resnet50_finetune(fine_tune_at=120)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:42.851487Z","iopub.execute_input":"2025-08-12T13:31:42.852028Z","iopub.status.idle":"2025-08-12T13:31:42.860875Z","shell.execute_reply.started":"2025-08-12T13:31:42.852001Z","shell.execute_reply":"2025-08-12T13:31:42.860361Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model optimization using OPTUNA for Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"!pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:22:56.471178Z","iopub.execute_input":"2025-08-12T07:22:56.471712Z","iopub.status.idle":"2025-08-12T07:23:00.298141Z","shell.execute_reply.started":"2025-08-12T07:22:56.471687Z","shell.execute_reply":"2025-08-12T07:23:00.297395Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import optuna\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ndef objective(trial):\n    # Search space\n    dense_units = trial.suggest_categorical(\"dense_units\", [64, 84, 128, 256])\n    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.3, 0.7)\n    l2_reg = trial.suggest_float(\"l2_reg\", 1e-5, 1e-2, log=True)\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n    fine_tune_at = trial.suggest_int(\"fine_tune_at\", 100, 150)\n    cw_autistic = trial.suggest_float(\"cw_autistic\", 0.8, 1.5)\n    cw_non_autistic = trial.suggest_float(\"cw_non_autistic\", 0.8, 1.5)\n\n    # Model\n    base_model = tf.keras.applications.ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224,224,3)\n    )\n    base_model.trainable = True\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(dense_units, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)),\n        layers.Dropout(dropout_rate),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=learning_rate),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n    ]\n\n    class_weights = {0: cw_non_autistic, 1: cw_autistic}\n\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=15,  # Lower for tuning speed\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=0\n    )\n\n    val_acc = max(history.history['val_accuracy'])\n\n    # Save best model weights for current trial\n    # model.save_weights(f\"/kaggle/working/model_trial_{trial.number}.weights.h5\")\n    # Save best model for current trial\n    model.save(f\"/kaggle/working/model_trial_{trial.number}.keras\")  # TensorFlow SavedModel format\n\n\n    return val_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:24:50.338411Z","iopub.execute_input":"2025-08-12T07:24:50.338854Z","iopub.status.idle":"2025-08-12T07:24:50.555171Z","shell.execute_reply.started":"2025-08-12T07:24:50.338826Z","shell.execute_reply":"2025-08-12T07:24:50.554615Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=10)  # Try 15 runs\n\nprint(\"Best trial:\", study.best_trial.params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:28:39.296011Z","iopub.execute_input":"2025-08-12T07:28:39.296571Z","iopub.status.idle":"2025-08-12T08:49:38.565103Z","shell.execute_reply.started":"2025-08-12T07:28:39.296550Z","shell.execute_reply":"2025-08-12T08:49:38.564482Z"}},"outputs":[{"name":"stderr","text":"[I 2025-08-12 07:28:39,297] A new study created in memory with name: no-name-a7dea6ae-bcc7-4a06-bfa8-57ca57bf344f\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1754983752.768679     103 service.cc:148] XLA service 0x7abbf4002ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1754983752.769472     103 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1754983755.415972     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1754983762.290281     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n[I 2025-08-12 07:36:19,364] Trial 0 finished with value: 0.9366438388824463 and parameters: {'dense_units': 256, 'dropout_rate': 0.4235363847214342, 'l2_reg': 0.00011482185941072048, 'learning_rate': 9.879824852833632e-05, 'fine_tune_at': 146, 'cw_autistic': 1.255434787703455, 'cw_non_autistic': 1.327191344277702}. Best is trial 0 with value: 0.9366438388824463.\n[I 2025-08-12 07:44:28,241] Trial 1 finished with value: 0.8090753555297852 and parameters: {'dense_units': 84, 'dropout_rate': 0.33759896840446, 'l2_reg': 1.2762512697695118e-05, 'learning_rate': 1.5077800480316522e-06, 'fine_tune_at': 114, 'cw_autistic': 1.1739403549245702, 'cw_non_autistic': 0.8141517855434596}. Best is trial 0 with value: 0.9366438388824463.\n[I 2025-08-12 07:52:44,511] Trial 2 finished with value: 0.9443492889404297 and parameters: {'dense_units': 256, 'dropout_rate': 0.32792881699035276, 'l2_reg': 0.00044048224110103157, 'learning_rate': 1.717631257431285e-05, 'fine_tune_at': 102, 'cw_autistic': 1.1667754741390135, 'cw_non_autistic': 0.9043860829232542}. Best is trial 2 with value: 0.9443492889404297.\n[I 2025-08-12 08:00:40,169] Trial 3 finished with value: 0.7816780805587769 and parameters: {'dense_units': 128, 'dropout_rate': 0.6473267296389054, 'l2_reg': 0.0007309770007497189, 'learning_rate': 1.272407005048123e-06, 'fine_tune_at': 137, 'cw_autistic': 1.4552747135252733, 'cw_non_autistic': 1.0063229831412621}. Best is trial 2 with value: 0.9443492889404297.\n[I 2025-08-12 08:08:46,015] Trial 4 finished with value: 0.8176369667053223 and parameters: {'dense_units': 64, 'dropout_rate': 0.30086531101730196, 'l2_reg': 0.0016273607104755376, 'learning_rate': 1.6811326790388017e-06, 'fine_tune_at': 120, 'cw_autistic': 1.3709456083702531, 'cw_non_autistic': 0.9661311069553262}. Best is trial 2 with value: 0.9443492889404297.\n[I 2025-08-12 08:16:39,760] Trial 5 finished with value: 0.9400684833526611 and parameters: {'dense_units': 84, 'dropout_rate': 0.3249600310283746, 'l2_reg': 1.051381145624428e-05, 'learning_rate': 2.6430428586218445e-05, 'fine_tune_at': 144, 'cw_autistic': 1.3280103793350257, 'cw_non_autistic': 1.028426991982168}. Best is trial 2 with value: 0.9443492889404297.\n[I 2025-08-12 08:24:53,136] Trial 6 finished with value: 0.8441780805587769 and parameters: {'dense_units': 256, 'dropout_rate': 0.3804788416388818, 'l2_reg': 0.003122933831872098, 'learning_rate': 3.4067634052429984e-06, 'fine_tune_at': 117, 'cw_autistic': 1.1348864728672237, 'cw_non_autistic': 0.8694571308738512}. Best is trial 2 with value: 0.9443492889404297.\n[I 2025-08-12 08:33:22,923] Trial 7 finished with value: 0.9452054500579834 and parameters: {'dense_units': 128, 'dropout_rate': 0.4187845256515822, 'l2_reg': 0.000497250308351491, 'learning_rate': 7.417948021074986e-05, 'fine_tune_at': 118, 'cw_autistic': 1.233759421780937, 'cw_non_autistic': 0.9700421364904332}. Best is trial 7 with value: 0.9452054500579834.\n[I 2025-08-12 08:41:39,870] Trial 8 finished with value: 0.8347602486610413 and parameters: {'dense_units': 64, 'dropout_rate': 0.5152354868145764, 'l2_reg': 0.006687616801207893, 'learning_rate': 3.52106531446752e-06, 'fine_tune_at': 130, 'cw_autistic': 1.2952735459837776, 'cw_non_autistic': 1.3847156006046646}. Best is trial 7 with value: 0.9452054500579834.\n[I 2025-08-12 08:49:38,560] Trial 9 finished with value: 0.8433219194412231 and parameters: {'dense_units': 64, 'dropout_rate': 0.6663702617394238, 'l2_reg': 5.84230312820608e-05, 'learning_rate': 4.750388845115908e-06, 'fine_tune_at': 142, 'cw_autistic': 1.497338176701787, 'cw_non_autistic': 1.166979649054924}. Best is trial 7 with value: 0.9452054500579834.\n","output_type":"stream"},{"name":"stdout","text":"Best trial: {'dense_units': 128, 'dropout_rate': 0.4187845256515822, 'l2_reg': 0.000497250308351491, 'learning_rate': 7.417948021074986e-05, 'fine_tune_at': 118, 'cw_autistic': 1.233759421780937, 'cw_non_autistic': 0.9700421364904332}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Best params, trial 2 and 7 from optuna hyparameter tuning","metadata":{}},{"cell_type":"markdown","source":"[I 2025-08-12 07:52:44,511] **Trial 2** finished with value: **0.9443492889404297**\n\n**Parameters**: {'dense_units': 256, 'dropout_rate': 0.32792881699035276, 'l2_reg': 0.00044048224110103157, 'learning_rate': 1.717631257431285e-05, 'fine_tune_at': 102, 'cw_autistic': 1.1667754741390135, 'cw_non_autistic': 0.9043860829232542}. \n","metadata":{}},{"cell_type":"markdown","source":"[I 2025-08-12 08:33:22,923] **Trial 7** finished with value: **0.9452054500579834** \n\n**Parameters**: {'dense_units': 128, 'dropout_rate': 0.4187845256515822, 'l2_reg': 0.000497250308351491, 'learning_rate': 7.417948021074986e-05, 'fine_tune_at': 118, 'cw_autistic': 1.233759421780937, 'cw_non_autistic': 0.9700421364904332}. ","metadata":{}},{"cell_type":"markdown","source":"## **Running the best model using the best hyperparameters (trial 7's)**","metadata":{}},{"cell_type":"code","source":"# best_params = study.best_trial.params\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Explicit input tensor\ninput_tensor = Input(shape=(224, 224, 3))\nbase_model = tf.keras.applications.ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_shape=input_tensor\n)\nbase_model.trainable = True\nfor layer in base_model.layers[:118]:\n    layer.trainable = False\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.000497250308351491)),\n    layers.Dropout(0.42),\n    layers.Dense(1, activation='sigmoid')\n])\n\nfinal_model.compile(\n    optimizer=Adam(learning_rate=7e-05),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nfinal_callbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n]\n\n# final_class_weights = {0: best_params['cw_autistic'], 1: best_params['cw_non_autistic']}\nfinal_class_weights = {0: 1.2, 1: 0.97}\n\nfinal_model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=30,\n    callbacks=final_callbacks,\n    class_weight=final_class_weights\n)\n\nfinal_model.save(\"/kaggle/working/resnet50_autism_best_model3.keras\")\nprint(\"✅ Best tuned model saved for FastAPI.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T12:42:41.312927Z","iopub.execute_input":"2025-08-12T12:42:41.313689Z","iopub.status.idle":"2025-08-12T12:42:41.342530Z","shell.execute_reply.started":"2025-08-12T12:42:41.313663Z","shell.execute_reply":"2025-08-12T12:42:41.341767Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/892456181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Explicit input tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m base_model = tf.keras.applications.ResNet50(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack_residual_blocks_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     return ResNet(\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mpreact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 )\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"channels_first\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A symbolic KerasTensor cannot be used as a boolean.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: A symbolic KerasTensor cannot be used as a boolean."],"ename":"TypeError","evalue":"A symbolic KerasTensor cannot be used as a boolean.","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"from tensorflow.keras import Input, Model, regularizers, layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Explicit input tensor\ninput_tensor = Input(shape=(224, 224, 3))\nbase_model = ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_tensor=input_tensor  # correct usage\n)\nbase_model.trainable = True\nfor layer in base_model.layers[:118]:\n    layer.trainable = False\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu',\n                 kernel_regularizer=regularizers.l2(0.000497250308351491)),\n    layers.Dropout(0.42),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=7e-05),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nfinal_callbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n]\n\nfinal_class_weights = {0: 1.2, 1: 0.97}\n\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=30,\n    callbacks=final_callbacks,\n    class_weight=final_class_weights\n)\n\nmodel.save(\"/kaggle/working/resnet50_autism_best_model3.keras\")\nprint(\"✅ Best tuned model saved for FastAPI.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T12:43:52.512116Z","iopub.execute_input":"2025-08-12T12:43:52.512451Z","iopub.status.idle":"2025-08-12T12:54:52.241980Z","shell.execute_reply.started":"2025-08-12T12:43:52.512426Z","shell.execute_reply":"2025-08-12T12:54:52.241202Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_8']\nReceived: inputs=Tensor(shape=(None, 224, 224, 3))\n  warnings.warn(msg)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1755002666.299625     105 service.cc:148] XLA service 0x7a9ba0003010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1755002666.300443     105 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1755002666.300460     105 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1755002669.292347     105 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1755002681.937868     105 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 359ms/step - accuracy: 0.6974 - loss: 0.7378 - val_accuracy: 0.8202 - val_loss: 0.5390 - learning_rate: 7.0000e-05\nEpoch 2/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 221ms/step - accuracy: 0.8458 - loss: 0.4856 - val_accuracy: 0.8647 - val_loss: 0.4408 - learning_rate: 7.0000e-05\nEpoch 3/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 219ms/step - accuracy: 0.8882 - loss: 0.3850 - val_accuracy: 0.8818 - val_loss: 0.4613 - learning_rate: 7.0000e-05\nEpoch 4/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 219ms/step - accuracy: 0.9283 - loss: 0.3132 - val_accuracy: 0.8913 - val_loss: 0.3917 - learning_rate: 7.0000e-05\nEpoch 5/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 222ms/step - accuracy: 0.9363 - loss: 0.2771 - val_accuracy: 0.8870 - val_loss: 0.4303 - learning_rate: 7.0000e-05\nEpoch 6/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 219ms/step - accuracy: 0.9495 - loss: 0.2462 - val_accuracy: 0.8622 - val_loss: 0.7152 - learning_rate: 7.0000e-05\nEpoch 7/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 222ms/step - accuracy: 0.9642 - loss: 0.2140 - val_accuracy: 0.8930 - val_loss: 0.4357 - learning_rate: 7.0000e-05\nEpoch 8/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 218ms/step - accuracy: 0.9722 - loss: 0.1919 - val_accuracy: 0.9298 - val_loss: 0.3382 - learning_rate: 3.5000e-05\nEpoch 9/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 218ms/step - accuracy: 0.9805 - loss: 0.1587 - val_accuracy: 0.9358 - val_loss: 0.3293 - learning_rate: 3.5000e-05\nEpoch 10/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 217ms/step - accuracy: 0.9889 - loss: 0.1327 - val_accuracy: 0.9435 - val_loss: 0.2964 - learning_rate: 3.5000e-05\nEpoch 14/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 214ms/step - accuracy: 0.9913 - loss: 0.1272 - val_accuracy: 0.9461 - val_loss: 0.3277 - learning_rate: 3.5000e-05\nEpoch 15/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 222ms/step - accuracy: 0.9900 - loss: 0.1308 - val_accuracy: 0.9341 - val_loss: 0.3879 - learning_rate: 3.5000e-05\nEpoch 16/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 216ms/step - accuracy: 0.9923 - loss: 0.1249 - val_accuracy: 0.9452 - val_loss: 0.3563 - learning_rate: 3.5000e-05\nEpoch 17/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 217ms/step - accuracy: 0.9933 - loss: 0.1167 - val_accuracy: 0.9529 - val_loss: 0.3131 - learning_rate: 1.7500e-05\nEpoch 18/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 220ms/step - accuracy: 0.9948 - loss: 0.1104 - val_accuracy: 0.9538 - val_loss: 0.3092 - learning_rate: 1.7500e-05\n✅ Best tuned model saved for FastAPI.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input, Model, regularizers, layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Define input tensor\ninput_tensor = Input(shape=(224, 224, 3))\n\n# Load the ResNet50 base model with pretrained ImageNet weights and without top layers\nbase_model = ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_tensor=input_tensor\n)\n\n# Freeze the layers up to the specified layer for fine-tuning\nbase_model.trainable = True\nfor layer in base_model.layers[:118]:\n    layer.trainable = False\n\n# Add custom head on top of the base model\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(\n    128,\n    activation='relu',\n    kernel_regularizer=regularizers.l2(0.000497250308351491)\n)(x)\nx = layers.Dropout(0.42)(x)\noutput = layers.Dense(1, activation='sigmoid')(x)\n\n# Build the final model\nmodel = Model(inputs=input_tensor, outputs=output)\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=7e-5),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# Prepare callbacks\nfinal_callbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n]\n\n# Use class weights as per your setup\nfinal_class_weights = {0: 1.2, 1: 0.97}\n\n# Train the model\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=30,\n    callbacks=final_callbacks,\n    class_weight=final_class_weights\n)\n\n# Save the full model for later loading (in FastAPI, etc.)\nmodel.save(\"/kaggle/working/resnet50_autism_best_model4.keras\")\nprint(\"✅ Best tuned model saved for FastAPI.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T13:31:56.560472Z","iopub.execute_input":"2025-08-12T13:31:56.561053Z","iopub.status.idle":"2025-08-12T13:41:17.195287Z","shell.execute_reply.started":"2025-08-12T13:31:56.561028Z","shell.execute_reply":"2025-08-12T13:41:17.194462Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1755005551.036968     102 service.cc:148] XLA service 0x7af484002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1755005551.037613     102 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1755005554.125732     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/146\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.7109 - loss: 0.7741   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1755005564.119135     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 314ms/step - accuracy: 0.7195 - loss: 0.7019 - val_accuracy: 0.7962 - val_loss: 0.5349 - learning_rate: 7.0000e-05\nEpoch 2/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 193ms/step - accuracy: 0.8523 - loss: 0.4853 - val_accuracy: 0.8031 - val_loss: 0.6708 - learning_rate: 7.0000e-05\nEpoch 3/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 195ms/step - accuracy: 0.8924 - loss: 0.3890 - val_accuracy: 0.8142 - val_loss: 0.6808 - learning_rate: 7.0000e-05\nEpoch 4/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 200ms/step - accuracy: 0.9217 - loss: 0.3353 - val_accuracy: 0.8767 - val_loss: 0.4545 - learning_rate: 7.0000e-05\nEpoch 5/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 196ms/step - accuracy: 0.9412 - loss: 0.2781 - val_accuracy: 0.9033 - val_loss: 0.3875 - learning_rate: 7.0000e-05\nEpoch 6/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 196ms/step - accuracy: 0.9674 - loss: 0.2197 - val_accuracy: 0.9127 - val_loss: 0.3823 - learning_rate: 7.0000e-05\nEpoch 7/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 196ms/step - accuracy: 0.9634 - loss: 0.2202 - val_accuracy: 0.9050 - val_loss: 0.4146 - learning_rate: 7.0000e-05\nEpoch 8/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 197ms/step - accuracy: 0.9636 - loss: 0.1998 - val_accuracy: 0.9118 - val_loss: 0.3768 - learning_rate: 7.0000e-05\nEpoch 9/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 194ms/step - accuracy: 0.9655 - loss: 0.2020 - val_accuracy: 0.9024 - val_loss: 0.4128 - learning_rate: 7.0000e-05\nEpoch 10/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 191ms/step - accuracy: 0.9693 - loss: 0.1822 - val_accuracy: 0.8579 - val_loss: 1.0631 - learning_rate: 7.0000e-05\nEpoch 11/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 191ms/step - accuracy: 0.9768 - loss: 0.1683 - val_accuracy: 0.9358 - val_loss: 0.3786 - learning_rate: 7.0000e-05\nEpoch 12/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 194ms/step - accuracy: 0.9885 - loss: 0.1310 - val_accuracy: 0.9486 - val_loss: 0.3077 - learning_rate: 3.5000e-05\nEpoch 13/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 193ms/step - accuracy: 0.9936 - loss: 0.1202 - val_accuracy: 0.9452 - val_loss: 0.3504 - learning_rate: 3.5000e-05\nEpoch 14/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 195ms/step - accuracy: 0.9932 - loss: 0.1175 - val_accuracy: 0.9443 - val_loss: 0.3565 - learning_rate: 3.5000e-05\nEpoch 15/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 193ms/step - accuracy: 0.9963 - loss: 0.1098 - val_accuracy: 0.9418 - val_loss: 0.3724 - learning_rate: 3.5000e-05\nEpoch 16/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 196ms/step - accuracy: 0.9930 - loss: 0.1125 - val_accuracy: 0.9555 - val_loss: 0.3206 - learning_rate: 1.7500e-05\nEpoch 17/30\n\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 195ms/step - accuracy: 0.9943 - loss: 0.1078 - val_accuracy: 0.9486 - val_loss: 0.3225 - learning_rate: 1.7500e-05\n✅ Best tuned model saved for FastAPI.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow import keras\n\nmodel_path = \"/kaggle/working/resnet50_autism_best_model2.keras\"\nmodel = keras.models.load_model(model_path)\n\n# Test loading\nprint(model.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T11:02:30.799706Z","iopub.execute_input":"2025-08-12T11:02:30.800326Z","iopub.status.idle":"2025-08-12T11:02:32.640813Z","shell.execute_reply.started":"2025-08-12T11:02:30.800303Z","shell.execute_reply":"2025-08-12T11:02:32.640180Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_12\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_11     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │       \u001b[38;5;34m172,116\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m85\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_11     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">172,116</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,061,629\u001b[0m (225.30 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,061,629</span> (225.30 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,650,857\u001b[0m (67.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,650,857</span> (67.33 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,109,056\u001b[0m (23.30 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,109,056</span> (23.30 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m35,301,716\u001b[0m (134.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,301,716</span> (134.67 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ndef preprocess_image(img_path, target_size=(224, 224)):\n    img = image.load_img(img_path, target_size=target_size)  # Load image\n    img_array = image.img_to_array(img)                      # Convert to array\n    img_array = np.expand_dims(img_array, axis=0)            # Add batch dimension\n    # img_array /= 255.0                                       # Normalize (if trained that way)\n    return img_array\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T11:08:47.814183Z","iopub.execute_input":"2025-08-12T11:08:47.814755Z","iopub.status.idle":"2025-08-12T11:08:47.818977Z","shell.execute_reply.started":"2025-08-12T11:08:47.814732Z","shell.execute_reply":"2025-08-12T11:08:47.817973Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# function for making predictions\n\ndef pred_aut(img_path):\n    \n    # Preprocess\n    processed_img = preprocess_image(img_path)\n    \n    # Predict\n    pred = model.predict(processed_img)\n    \n    # Interpret output\n    # predicted_class = np.argmax(pred, axis=1)\n    # print(f\"Predicted Class: {predicted_class}\")\n    print(f\"Pred probability: {pred}\")\n    \n\n    return \"Autistic\" if pred < 0.5 else \"Not Autistic\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T11:08:48.894613Z","iopub.execute_input":"2025-08-12T11:08:48.894919Z","iopub.status.idle":"2025-08-12T11:08:48.899295Z","shell.execute_reply.started":"2025-08-12T11:08:48.894897Z","shell.execute_reply":"2025-08-12T11:08:48.898472Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"pred_aut(\"/kaggle/input/real-test/image (7).jpeg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T11:28:36.254949Z","iopub.execute_input":"2025-08-12T11:28:36.255261Z","iopub.status.idle":"2025-08-12T11:28:40.728169Z","shell.execute_reply.started":"2025-08-12T11:28:36.255242Z","shell.execute_reply":"2025-08-12T11:28:40.727563Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\nPred probability: [[1.9573296e-05]]\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"'Autistic'"},"metadata":{}}],"execution_count":103},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# ----------------------------\n# 1. Load the model\n# ----------------------------\nmodel_path = \"/kaggle/working/resnet50_autism_best_model2.keras\"  # Update if needed\nmodel = load_model(model_path)\n\n# ----------------------------\n# 2. Test data setup\n# ----------------------------\ntest_dir = \"/kaggle/input/autism/autism_split/test\"  # Directory with 'autistic' & 'non_autistic' folders\n\nimg_height, img_width = 224, 224  # Change if your model expects different size\nbatch_size = 32\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=False\n)\n\n# ----------------------------\n# 3. Predictions\n# ----------------------------\npred_probs = model.predict(test_generator)\npred_classes = (pred_probs > 0.5).astype(int).ravel()\n\n# ----------------------------\n# 4. Metrics\n# ----------------------------\ntrue_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys())\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_classes, pred_classes, target_names=class_labels))\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(true_classes, pred_classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T11:27:37.310346Z","iopub.execute_input":"2025-08-12T11:27:37.311277Z","iopub.status.idle":"2025-08-12T11:27:43.675857Z","shell.execute_reply.started":"2025-08-12T11:27:37.311250Z","shell.execute_reply":"2025-08-12T11:27:43.674929Z"}},"outputs":[{"name":"stdout","text":"Found 24 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    autistic       0.50      1.00      0.67        12\nnon_autistic       0.00      0.00      0.00        12\n\n    accuracy                           0.50        24\n   macro avg       0.25      0.50      0.33        24\nweighted avg       0.25      0.50      0.33        24\n\n\nConfusion Matrix:\n[[12  0]\n [12  0]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":102},{"cell_type":"markdown","source":"# resave the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model(\"/kaggle/working/resnet50_autism_best_model2.keras\", compile=False)\nmodel.save(\"/kaggle/working/resnet50_autism_safe.keras\", save_format=\"keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T12:33:29.167664Z","iopub.execute_input":"2025-08-12T12:33:29.167936Z","iopub.status.idle":"2025-08-12T12:33:29.184068Z","shell.execute_reply.started":"2025-08-12T12:33:29.167916Z","shell.execute_reply":"2025-08-12T12:33:29.183145Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3388328959.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/resnet50_autism_best_model2.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/resnet50_autism_safe.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: File not found: filepath=/kaggle/working/resnet50_autism_best_model2.keras. Please ensure the file is an accessible `.keras` zip file."],"ename":"ValueError","evalue":"File not found: filepath=/kaggle/working/resnet50_autism_best_model2.keras. Please ensure the file is an accessible `.keras` zip file.","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}